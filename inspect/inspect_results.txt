[MODEL INFO]:
________________________________________________________________________________________________________________________
Model Name: model_3
________________________________________________________________________________________________________________________
ID          Name                    Type                    Device      Notes                                           
========================================================================================================================
0/68        input_41                InputLayer              INPUT                                                       
------------------------------------------------------------------------------------------------------------------------
1/68        conv2d_60               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
2/68        batch_normalization_60  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
3/68        re_lu_51                ReLU                    DPU                                                         
------------------------------------------------------------------------------------------------------------------------
4/68        conv2d_61               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
5/68        batch_normalization_61  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
6/68        re_lu_52                ReLU                    DPU                                                         
------------------------------------------------------------------------------------------------------------------------
7/68        conv2d_62               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
8/68        batch_normalization_62  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
9/68        add_24                  Add                     DPU                                                         
------------------------------------------------------------------------------------------------------------------------
10/68       re_lu_53                ReLU                    DPU                                                         
------------------------------------------------------------------------------------------------------------------------
11/68       conv2d_63               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
12/68       batch_normalization_63  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
13/68       re_lu_54                ReLU                    DPU                                                         
------------------------------------------------------------------------------------------------------------------------
14/68       conv2d_64               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
15/68       batch_normalization_64  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
16/68       add_25                  Add                     DPU                                                         
------------------------------------------------------------------------------------------------------------------------
17/68       re_lu_55                ReLU                    DPU                                                         
------------------------------------------------------------------------------------------------------------------------
18/68       conv2d_66               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
19/68       batch_normalization_66  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
20/68       re_lu_56                ReLU                    DPU                                                         
------------------------------------------------------------------------------------------------------------------------
21/68       conv2d_67               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
22/68       conv2d_65               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
23/68       batch_normalization_67  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
24/68       batch_normalization_65  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
25/68       add_26                  Add                     DPU                                                         
------------------------------------------------------------------------------------------------------------------------
26/68       re_lu_57                ReLU                    DPU                                                         
------------------------------------------------------------------------------------------------------------------------
27/68       conv2d_68               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
28/68       batch_normalization_68  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
29/68       re_lu_58                ReLU                    DPU                                                         
------------------------------------------------------------------------------------------------------------------------
30/68       conv2d_69               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
31/68       batch_normalization_69  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
32/68       add_27                  Add                     DPU                                                         
------------------------------------------------------------------------------------------------------------------------
33/68       re_lu_59                ReLU                    DPU                                                         
------------------------------------------------------------------------------------------------------------------------
34/68       conv2d_71               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
35/68       batch_normalization_71  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
36/68       re_lu_60                ReLU                    DPU                                                         
------------------------------------------------------------------------------------------------------------------------
37/68       conv2d_72               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
38/68       conv2d_70               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
39/68       batch_normalization_72  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
40/68       batch_normalization_70  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
41/68       add_28                  Add                     DPU                                                         
------------------------------------------------------------------------------------------------------------------------
42/68       re_lu_61                ReLU                    DPU                                                         
------------------------------------------------------------------------------------------------------------------------
43/68       conv2d_73               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
44/68       batch_normalization_73  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
45/68       re_lu_62                ReLU                    DPU                                                         
------------------------------------------------------------------------------------------------------------------------
46/68       conv2d_74               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
47/68       batch_normalization_74  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
48/68       add_29                  Add                     DPU                                                         
------------------------------------------------------------------------------------------------------------------------
49/68       re_lu_63                ReLU                    DPU                                                         
------------------------------------------------------------------------------------------------------------------------
50/68       conv2d_76               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
51/68       batch_normalization_76  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
52/68       re_lu_64                ReLU                    DPU                                                         
------------------------------------------------------------------------------------------------------------------------
53/68       conv2d_77               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
54/68       conv2d_75               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
55/68       batch_normalization_77  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
56/68       batch_normalization_75  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
57/68       add_30                  Add                     DPU                                                         
------------------------------------------------------------------------------------------------------------------------
58/68       re_lu_65                ReLU                    DPU                                                         
------------------------------------------------------------------------------------------------------------------------
59/68       conv2d_78               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
60/68       batch_normalization_78  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
61/68       re_lu_66                ReLU                    DPU                                                         
------------------------------------------------------------------------------------------------------------------------
62/68       conv2d_79               Conv2D<linear>          DPU                                                         
------------------------------------------------------------------------------------------------------------------------
63/68       batch_normalization_79  BatchNormalization      DPU                                                         
------------------------------------------------------------------------------------------------------------------------
64/68       add_31                  Add                     DPU                                                         
------------------------------------------------------------------------------------------------------------------------
65/68       re_lu_67                ReLU                    DPU                                                         
------------------------------------------------------------------------------------------------------------------------
66/68       average_pooling2d_3     AveragePooling2D        DPU                                                         
------------------------------------------------------------------------------------------------------------------------
67/68       flatten_3               Flatten                 DPU                                                         
------------------------------------------------------------------------------------------------------------------------
68/68       dense_3                 Dense<softmax>          DPU+CPU     Seperate layer activation `softmax`; `softmax`  
                                                                        is not supported by target                      
------------------------------------------------------------------------------------------------------------------------
========================================================================================================================
[SUMMARY INFO]:
- [Target Name]: DPUCZDX8G_ISA1_B4096
- [Total Layers]: 69
- [Layer Types]: InputLayer(1) Conv2D<linear>(20) BatchNormalization(20) ReLU(17) Add(8) AveragePooling2D(1) Flatten(1) Dense<softmax>(1) 
- [Partition Results]: INPUT(1) DPU(67) DPU+CPU(1) 
========================================================================================================================
[NOTES INFO]:
- [68/68] Layer dense_3 (Type:Dense<softmax>, Device:DPU+CPU):
    * Seperate layer activation `softmax`
    * `softmax` is not supported by target
========================================================================================================================

Detailed Model Info: 

Layer ID: 0
Layer Name: input_41
Layer Type: InputLayer
Device: INPUT
Notes: 
    None
Layer Config:
{'batch_input_shape': (None, 32, 32, 3),
 'dtype': 'float32',
 'name': 'input_41',
 'ragged': False,
 'sparse': False}
________________________________________________________________________________________________________________________
Layer ID: 1
Layer Name: conv2d_60
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 64,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'HeNormal', 'config': {'seed': None}},
 'kernel_regularizer': None,
 'kernel_size': (3, 3),
 'name': 'conv2d_60',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': True}
________________________________________________________________________________________________________________________
Layer ID: 2
Layer Name: batch_normalization_60
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_60.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_60',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 3
Layer Name: re_lu_51
Layer Type: ReLU
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32',
 'max_value': None,
 'name': 're_lu_51',
 'negative_slope': array(0., dtype=float32),
 'threshold': array(0., dtype=float32),
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 4
Layer Name: conv2d_61
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 64,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'HeNormal', 'config': {'seed': None}},
 'kernel_regularizer': None,
 'kernel_size': (3, 3),
 'name': 'conv2d_61',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': True}
________________________________________________________________________________________________________________________
Layer ID: 5
Layer Name: batch_normalization_61
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_61.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_61',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 6
Layer Name: re_lu_52
Layer Type: ReLU
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32',
 'max_value': None,
 'name': 're_lu_52',
 'negative_slope': array(0., dtype=float32),
 'threshold': array(0., dtype=float32),
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 7
Layer Name: conv2d_62
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 64,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'HeNormal', 'config': {'seed': None}},
 'kernel_regularizer': None,
 'kernel_size': (3, 3),
 'name': 'conv2d_62',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': True}
________________________________________________________________________________________________________________________
Layer ID: 8
Layer Name: batch_normalization_62
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_62.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_62',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 9
Layer Name: add_24
Layer Type: Add
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32', 'name': 'add_24', 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 10
Layer Name: re_lu_53
Layer Type: ReLU
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32',
 'max_value': None,
 'name': 're_lu_53',
 'negative_slope': array(0., dtype=float32),
 'threshold': array(0., dtype=float32),
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 11
Layer Name: conv2d_63
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 64,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'HeNormal', 'config': {'seed': None}},
 'kernel_regularizer': None,
 'kernel_size': (3, 3),
 'name': 'conv2d_63',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': True}
________________________________________________________________________________________________________________________
Layer ID: 12
Layer Name: batch_normalization_63
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_63.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_63',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 13
Layer Name: re_lu_54
Layer Type: ReLU
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32',
 'max_value': None,
 'name': 're_lu_54',
 'negative_slope': array(0., dtype=float32),
 'threshold': array(0., dtype=float32),
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 14
Layer Name: conv2d_64
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 64,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'HeNormal', 'config': {'seed': None}},
 'kernel_regularizer': None,
 'kernel_size': (3, 3),
 'name': 'conv2d_64',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': True}
________________________________________________________________________________________________________________________
Layer ID: 15
Layer Name: batch_normalization_64
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_64.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_64',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 16
Layer Name: add_25
Layer Type: Add
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32', 'name': 'add_25', 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 17
Layer Name: re_lu_55
Layer Type: ReLU
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32',
 'max_value': None,
 'name': 're_lu_55',
 'negative_slope': array(0., dtype=float32),
 'threshold': array(0., dtype=float32),
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 18
Layer Name: conv2d_66
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 128,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'HeNormal', 'config': {'seed': None}},
 'kernel_regularizer': None,
 'kernel_size': (3, 3),
 'name': 'conv2d_66',
 'padding': 'same',
 'strides': (2, 2),
 'trainable': True,
 'use_bias': True}
________________________________________________________________________________________________________________________
Layer ID: 19
Layer Name: batch_normalization_66
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_66.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_66',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 20
Layer Name: re_lu_56
Layer Type: ReLU
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32',
 'max_value': None,
 'name': 're_lu_56',
 'negative_slope': array(0., dtype=float32),
 'threshold': array(0., dtype=float32),
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 21
Layer Name: conv2d_67
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 128,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'HeNormal', 'config': {'seed': None}},
 'kernel_regularizer': None,
 'kernel_size': (3, 3),
 'name': 'conv2d_67',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': True}
________________________________________________________________________________________________________________________
Layer ID: 22
Layer Name: conv2d_65
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 128,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'HeNormal', 'config': {'seed': None}},
 'kernel_regularizer': None,
 'kernel_size': (1, 1),
 'name': 'conv2d_65',
 'padding': 'same',
 'strides': (2, 2),
 'trainable': True,
 'use_bias': True}
________________________________________________________________________________________________________________________
Layer ID: 23
Layer Name: batch_normalization_67
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_67.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_67',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 24
Layer Name: batch_normalization_65
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_65.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_65',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 25
Layer Name: add_26
Layer Type: Add
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32', 'name': 'add_26', 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 26
Layer Name: re_lu_57
Layer Type: ReLU
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32',
 'max_value': None,
 'name': 're_lu_57',
 'negative_slope': array(0., dtype=float32),
 'threshold': array(0., dtype=float32),
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 27
Layer Name: conv2d_68
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 128,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'HeNormal', 'config': {'seed': None}},
 'kernel_regularizer': None,
 'kernel_size': (3, 3),
 'name': 'conv2d_68',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': True}
________________________________________________________________________________________________________________________
Layer ID: 28
Layer Name: batch_normalization_68
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_68.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_68',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 29
Layer Name: re_lu_58
Layer Type: ReLU
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32',
 'max_value': None,
 'name': 're_lu_58',
 'negative_slope': array(0., dtype=float32),
 'threshold': array(0., dtype=float32),
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 30
Layer Name: conv2d_69
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 128,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'HeNormal', 'config': {'seed': None}},
 'kernel_regularizer': None,
 'kernel_size': (3, 3),
 'name': 'conv2d_69',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': True}
________________________________________________________________________________________________________________________
Layer ID: 31
Layer Name: batch_normalization_69
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_69.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_69',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 32
Layer Name: add_27
Layer Type: Add
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32', 'name': 'add_27', 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 33
Layer Name: re_lu_59
Layer Type: ReLU
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32',
 'max_value': None,
 'name': 're_lu_59',
 'negative_slope': array(0., dtype=float32),
 'threshold': array(0., dtype=float32),
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 34
Layer Name: conv2d_71
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 256,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'HeNormal', 'config': {'seed': None}},
 'kernel_regularizer': None,
 'kernel_size': (3, 3),
 'name': 'conv2d_71',
 'padding': 'same',
 'strides': (2, 2),
 'trainable': True,
 'use_bias': True}
________________________________________________________________________________________________________________________
Layer ID: 35
Layer Name: batch_normalization_71
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_71.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_71',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 36
Layer Name: re_lu_60
Layer Type: ReLU
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32',
 'max_value': None,
 'name': 're_lu_60',
 'negative_slope': array(0., dtype=float32),
 'threshold': array(0., dtype=float32),
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 37
Layer Name: conv2d_72
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 256,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'HeNormal', 'config': {'seed': None}},
 'kernel_regularizer': None,
 'kernel_size': (3, 3),
 'name': 'conv2d_72',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': True}
________________________________________________________________________________________________________________________
Layer ID: 38
Layer Name: conv2d_70
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 256,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'HeNormal', 'config': {'seed': None}},
 'kernel_regularizer': None,
 'kernel_size': (1, 1),
 'name': 'conv2d_70',
 'padding': 'same',
 'strides': (2, 2),
 'trainable': True,
 'use_bias': True}
________________________________________________________________________________________________________________________
Layer ID: 39
Layer Name: batch_normalization_72
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_72.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_72',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 40
Layer Name: batch_normalization_70
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_70.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_70',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 41
Layer Name: add_28
Layer Type: Add
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32', 'name': 'add_28', 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 42
Layer Name: re_lu_61
Layer Type: ReLU
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32',
 'max_value': None,
 'name': 're_lu_61',
 'negative_slope': array(0., dtype=float32),
 'threshold': array(0., dtype=float32),
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 43
Layer Name: conv2d_73
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 256,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'HeNormal', 'config': {'seed': None}},
 'kernel_regularizer': None,
 'kernel_size': (3, 3),
 'name': 'conv2d_73',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': True}
________________________________________________________________________________________________________________________
Layer ID: 44
Layer Name: batch_normalization_73
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_73.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_73',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 45
Layer Name: re_lu_62
Layer Type: ReLU
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32',
 'max_value': None,
 'name': 're_lu_62',
 'negative_slope': array(0., dtype=float32),
 'threshold': array(0., dtype=float32),
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 46
Layer Name: conv2d_74
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 256,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'HeNormal', 'config': {'seed': None}},
 'kernel_regularizer': None,
 'kernel_size': (3, 3),
 'name': 'conv2d_74',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': True}
________________________________________________________________________________________________________________________
Layer ID: 47
Layer Name: batch_normalization_74
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_74.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_74',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 48
Layer Name: add_29
Layer Type: Add
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32', 'name': 'add_29', 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 49
Layer Name: re_lu_63
Layer Type: ReLU
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32',
 'max_value': None,
 'name': 're_lu_63',
 'negative_slope': array(0., dtype=float32),
 'threshold': array(0., dtype=float32),
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 50
Layer Name: conv2d_76
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 512,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'HeNormal', 'config': {'seed': None}},
 'kernel_regularizer': None,
 'kernel_size': (3, 3),
 'name': 'conv2d_76',
 'padding': 'same',
 'strides': (2, 2),
 'trainable': True,
 'use_bias': True}
________________________________________________________________________________________________________________________
Layer ID: 51
Layer Name: batch_normalization_76
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_76.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_76',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 52
Layer Name: re_lu_64
Layer Type: ReLU
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32',
 'max_value': None,
 'name': 're_lu_64',
 'negative_slope': array(0., dtype=float32),
 'threshold': array(0., dtype=float32),
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 53
Layer Name: conv2d_77
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 512,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'HeNormal', 'config': {'seed': None}},
 'kernel_regularizer': None,
 'kernel_size': (3, 3),
 'name': 'conv2d_77',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': True}
________________________________________________________________________________________________________________________
Layer ID: 54
Layer Name: conv2d_75
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 512,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'HeNormal', 'config': {'seed': None}},
 'kernel_regularizer': None,
 'kernel_size': (1, 1),
 'name': 'conv2d_75',
 'padding': 'same',
 'strides': (2, 2),
 'trainable': True,
 'use_bias': True}
________________________________________________________________________________________________________________________
Layer ID: 55
Layer Name: batch_normalization_77
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_77.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_77',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 56
Layer Name: batch_normalization_75
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_75.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_75',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 57
Layer Name: add_30
Layer Type: Add
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32', 'name': 'add_30', 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 58
Layer Name: re_lu_65
Layer Type: ReLU
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32',
 'max_value': None,
 'name': 're_lu_65',
 'negative_slope': array(0., dtype=float32),
 'threshold': array(0., dtype=float32),
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 59
Layer Name: conv2d_78
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 512,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'HeNormal', 'config': {'seed': None}},
 'kernel_regularizer': None,
 'kernel_size': (3, 3),
 'name': 'conv2d_78',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': True}
________________________________________________________________________________________________________________________
Layer ID: 60
Layer Name: batch_normalization_78
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_78.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_78',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 61
Layer Name: re_lu_66
Layer Type: ReLU
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32',
 'max_value': None,
 'name': 're_lu_66',
 'negative_slope': array(0., dtype=float32),
 'threshold': array(0., dtype=float32),
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 62
Layer Name: conv2d_79
Layer Type: Conv2D
Device: DPU
Notes: 
    None
Layer Config:
{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'dtype': 'float32',
 'filters': 512,
 'groups': 1,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'HeNormal', 'config': {'seed': None}},
 'kernel_regularizer': None,
 'kernel_size': (3, 3),
 'name': 'conv2d_79',
 'padding': 'same',
 'strides': (1, 1),
 'trainable': True,
 'use_bias': True}
________________________________________________________________________________________________________________________
Layer ID: 63
Layer Name: batch_normalization_79
Layer Type: BatchNormalization
Device: DPU
Notes: 
    1. Folded into previous layer conv2d_79.
Layer Config:
{'axis': ListWrapper([3]),
 'beta_constraint': None,
 'beta_initializer': {'class_name': 'Zeros', 'config': {}},
 'beta_regularizer': None,
 'center': True,
 'dtype': 'float32',
 'epsilon': 0.001,
 'gamma_constraint': None,
 'gamma_initializer': {'class_name': 'Ones', 'config': {}},
 'gamma_regularizer': None,
 'momentum': 0.99,
 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},
 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},
 'name': 'batch_normalization_79',
 'scale': True,
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 64
Layer Name: add_31
Layer Type: Add
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32', 'name': 'add_31', 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 65
Layer Name: re_lu_67
Layer Type: ReLU
Device: DPU
Notes: 
    None
Layer Config:
{'dtype': 'float32',
 'max_value': None,
 'name': 're_lu_67',
 'negative_slope': array(0., dtype=float32),
 'threshold': array(0., dtype=float32),
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 66
Layer Name: average_pooling2d_3
Layer Type: AveragePooling2D
Device: DPU
Notes: 
    1. Converted to VitisAveragePooling2D.
Layer Config:
{'data_format': 'channels_last',
 'dtype': 'float32',
 'name': 'average_pooling2d_3',
 'padding': 'valid',
 'pool_size': (4, 4),
 'strides': (4, 4),
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 67
Layer Name: flatten_3
Layer Type: Flatten
Device: DPU
Notes: 
    None
Layer Config:
{'data_format': 'channels_last',
 'dtype': 'float32',
 'name': 'flatten_3',
 'trainable': True}
________________________________________________________________________________________________________________________
Layer ID: 68
Layer Name: dense_3
Layer Type: Dense
Device: DPU+CPU
Notes: 
    1. Seperate layer activation `softmax`.
    2. `softmax` is not supported by target.
Layer Config:
{'activation': 'softmax',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'dtype': 'float32',
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'GlorotUniform',
                        'config': {'seed': None}},
 'kernel_regularizer': None,
 'name': 'dense_3',
 'trainable': True,
 'units': 10,
 'use_bias': True}
________________________________________________________________________________________________________________________