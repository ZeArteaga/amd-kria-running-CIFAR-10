{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quick observation (AI)**:\n",
    "\n",
    "Some assistance for figuring out the keras/tensorflow API was provided by ChatGPT. Optimization of the parameters, however, was manual. There was also assistance to write the checkpoints/callbacks used in training. Everything else related to the model itself was written based on the original paper [here](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf) and different implementations across the web for ResNet-18 + some fine tuning. (e.g Data Augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/.local/lib/python3.8/site-packages/pip/_vendor/msgpack/__init__.py\", line 15, in <module>\n",
      "    from ._cmsgpack import Packer, unpackb, Unpacker\n",
      "ModuleNotFoundError: No module named 'pip._vendor.msgpack._cmsgpack'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/pip\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/home/jovyan/.local/lib/python3.8/site-packages/pip/_internal/cli/main.py\", line 78, in main\n",
      "    command = create_command(cmd_name, isolated=(\"--isolated\" in cmd_args))\n",
      "  File \"/home/jovyan/.local/lib/python3.8/site-packages/pip/_internal/commands/__init__.py\", line 114, in create_command\n",
      "    module = importlib.import_module(module_path)\n",
      "  File \"/usr/lib/python3.8/importlib/__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 848, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/home/jovyan/.local/lib/python3.8/site-packages/pip/_internal/commands/install.py\", line 16, in <module>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while terminating subprocess (pid=354): \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    from pip._internal.cli.req_command import (\n",
      "  File \"/home/jovyan/.local/lib/python3.8/site-packages/pip/_internal/cli/req_command.py\", line 18, in <module>\n",
      "    from pip._internal.index.collector import LinkCollector\n",
      "  File \"/home/jovyan/.local/lib/python3.8/site-packages/pip/_internal/index/collector.py\", line 38, in <module>\n",
      "    from pip._internal.network.session import PipSession\n",
      "  File \"/home/jovyan/.local/lib/python3.8/site-packages/pip/_internal/network/session.py\", line 33, in <module>\n",
      "    from pip._vendor.cachecontrol import CacheControlAdapter as _BaseCacheControlAdapter\n",
      "  File \"/home/jovyan/.local/lib/python3.8/site-packages/pip/_vendor/cachecontrol/__init__.py\", line 13, in <module>\n",
      "    from pip._vendor.cachecontrol.adapter import CacheControlAdapter\n",
      "  File \"/home/jovyan/.local/lib/python3.8/site-packages/pip/_vendor/cachecontrol/adapter.py\", line 14, in <module>\n",
      "    from pip._vendor.cachecontrol.controller import PERMANENT_REDIRECT_STATUSES, CacheController\n",
      "  File \"/home/jovyan/.local/lib/python3.8/site-packages/pip/_vendor/cachecontrol/controller.py\", line 20, in <module>\n",
      "    from pip._vendor.cachecontrol.serialize import Serializer\n",
      "  File \"/home/jovyan/.local/lib/python3.8/site-packages/pip/_vendor/cachecontrol/serialize.py\", line 9, in <module>\n",
      "    from pip._vendor import msgpack\n",
      "  File \"/home/jovyan/.local/lib/python3.8/site-packages/pip/_vendor/msgpack/__init__.py\", line 17, in <module>\n",
      "    from .fallback import Packer, unpackb, Unpacker\n",
      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 844, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 939, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1038, in get_data\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install --upgrade pip\n",
    "pip install numpy matplotlib keras tensorflow[and-cuda]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-08 11:36:27.655754: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-08 11:36:27.876533: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-08 11:36:29.645148: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2025-01-08 11:36:29.645276: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2025-01-08 11:36:29.645282: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Conv2D, AveragePooling2D, MaxPooling2D, GlobalAveragePooling2D, Dense, Flatten, BatchNormalization, Add, Input, ReLU\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Some requested devices in `tf.distribute.Strategy` are not visible to TensorFlow: /job:localhost/replica:0/task:0/device:GPU:0,/job:localhost/replica:0/task:0/device:GPU:1\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-08 11:36:36.751494: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: /usr/lib/x86_64-linux-gnu/libcuda.so.1: file too short; LD_LIBRARY_PATH: /usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2025-01-08 11:36:36.751516: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "# to use gpus on jupyter lab\n",
    "tf.debugging.set_log_device_placement(False)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "index_to_use = [0, 1] # add more depending on the server\n",
    "device_names = [f'/GPU:{i}' for i in index_to_use]\n",
    "strategy = tf.distribute.MirroredStrategy(devices=device_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#if using only CPU\n",
    "tf.debugging.set_log_device_placement(False)\n",
    "# Disable all GPUs\n",
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "#CIFAR-10 dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "print(train_images.shape)\n",
    "train_images = train_images.reshape(train_images.shape[0], 32, 32, 3) #ensure shape 32 W x 32 H x 3 channels for each image\n",
    "test_images = test_images.reshape(test_images.shape[0], 32, 32, 3)\n",
    "\n",
    "#range 0-1\n",
    "train_images = train_images.astype('float32') / 255.0\n",
    "test_images = test_images.astype('float32') / 255.0\n",
    "\n",
    "#One-hot encoding labels\n",
    "train_labels = to_categorical(train_labels, 10)\n",
    "test_labels = to_categorical(test_labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# functional API:\n",
    "# Define ResNetBlock as a function\n",
    "def ResNetBlock(x, n_filters, kernel_size=(3, 3), kernel_init='HeNormal', downsample=False):\n",
    "    strides = [2, 1] if downsample else [1, 1]\n",
    "    \n",
    "    # Residual connection - if downsampling, apply to the original input to match shapes\n",
    "    # for the shortcut connection (kernel size = 1 basically just merges RGB channels)\n",
    "    if downsample:\n",
    "        res = Conv2D(n_filters, kernel_size=(1, 1), strides=2, padding='same', kernel_initializer=kernel_init)(x)  # Apply downsampling to original input\n",
    "        res = BatchNormalization()(res)\n",
    "    else:\n",
    "        res = x  # When not downsampling, residual is just the output of the block\n",
    "    \n",
    "    # First convolution\n",
    "    x = Conv2D(n_filters, kernel_size, strides=strides[0], padding='same', kernel_initializer=kernel_init)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "        \n",
    "    # Second convolution\n",
    "    x = Conv2D(n_filters, kernel_size, strides=strides[1], padding='same', kernel_initializer=kernel_init)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    # Add the residual connection (skip connection)\n",
    "    x = Add()([x, res])\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "# Create the ResNet18 model using the functional API\n",
    "def ResNet18(input_shape=(32, 32, 3), n_classes=10):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    \n",
    "    # Initial part\n",
    "    x = Conv2D(64, (3, 3), strides=1, padding='same', kernel_initializer='HeNormal')(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    # Blocks - 2 x 2 blocks x 4 stages of convolution layers\n",
    "    x = ResNetBlock(x, 64, downsample=False)  # 64 filters, no downsampling\n",
    "    x = ResNetBlock(x, 64, downsample=False)\n",
    "    \n",
    "    x = ResNetBlock(x, 128, downsample=True)  # 128 filters, with downsampling\n",
    "    x = ResNetBlock(x, 128, downsample=False)\n",
    "    \n",
    "    x = ResNetBlock(x, 256, downsample=True)  # 256 filters, with downsampling\n",
    "    x = ResNetBlock(x, 256, downsample=False)\n",
    "    \n",
    "    x = ResNetBlock(x, 512, downsample=True)  # 512 filters, with downsampling\n",
    "    x = ResNetBlock(x, 512, downsample=False)\n",
    "\n",
    "    # Final part\n",
    "    #x = GlobalAveragePooling2D()(x) replaced by 2 lines below\n",
    "    x = AveragePooling2D(pool_size=(4, 4), strides=(4, 4), padding=\"valid\")(x)\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    output = Dense(n_classes, activation='softmax')(x)\n",
    "    \n",
    "    # Create the complete model\n",
    "    model = Model(inputs=input_tensor, outputs=output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Augmentation...\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 32, 32, 64)   1792        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 32, 32, 64)  256         ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                   (None, 32, 32, 64)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 32, 32, 64)   36928       ['re_lu[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 32, 32, 64)  256         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_1 (ReLU)                 (None, 32, 32, 64)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 32, 32, 64)   36928       ['re_lu_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 32, 32, 64)  256         ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 32, 32, 64)   0           ['batch_normalization_2[0][0]',  \n",
      "                                                                  're_lu[0][0]']                  \n",
      "                                                                                                  \n",
      " re_lu_2 (ReLU)                 (None, 32, 32, 64)   0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 32, 32, 64)   36928       ['re_lu_2[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 32, 32, 64)  256         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_3 (ReLU)                 (None, 32, 32, 64)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 32, 32, 64)   36928       ['re_lu_3[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 32, 32, 64)  256         ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 32, 32, 64)   0           ['batch_normalization_4[0][0]',  \n",
      "                                                                  're_lu_2[0][0]']                \n",
      "                                                                                                  \n",
      " re_lu_4 (ReLU)                 (None, 32, 32, 64)   0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 16, 16, 128)  73856       ['re_lu_4[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 16, 16, 128)  512        ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_5 (ReLU)                 (None, 16, 16, 128)  0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 16, 16, 128)  147584      ['re_lu_5[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 16, 16, 128)  8320        ['re_lu_4[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 16, 16, 128)  512        ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 16, 16, 128)  512        ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 16, 16, 128)  0           ['batch_normalization_7[0][0]',  \n",
      "                                                                  'batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " re_lu_6 (ReLU)                 (None, 16, 16, 128)  0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 16, 16, 128)  147584      ['re_lu_6[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 16, 16, 128)  512        ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_7 (ReLU)                 (None, 16, 16, 128)  0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 16, 16, 128)  147584      ['re_lu_7[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 16, 16, 128)  512        ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 16, 16, 128)  0           ['batch_normalization_9[0][0]',  \n",
      "                                                                  're_lu_6[0][0]']                \n",
      "                                                                                                  \n",
      " re_lu_8 (ReLU)                 (None, 16, 16, 128)  0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 8, 8, 256)    295168      ['re_lu_8[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_9 (ReLU)                 (None, 8, 8, 256)    0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 8, 8, 256)    590080      ['re_lu_9[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 8, 8, 256)    33024       ['re_lu_8[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 8, 8, 256)    0           ['batch_normalization_12[0][0]', \n",
      "                                                                  'batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_10 (ReLU)                (None, 8, 8, 256)    0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 8, 8, 256)    590080      ['re_lu_10[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_11 (ReLU)                (None, 8, 8, 256)    0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 8, 8, 256)    590080      ['re_lu_11[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 8, 8, 256)    0           ['batch_normalization_14[0][0]', \n",
      "                                                                  're_lu_10[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_12 (ReLU)                (None, 8, 8, 256)    0           ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 4, 4, 512)    1180160     ['re_lu_12[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 4, 4, 512)   2048        ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_13 (ReLU)                (None, 4, 4, 512)    0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 4, 4, 512)    2359808     ['re_lu_13[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 4, 4, 512)    131584      ['re_lu_12[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 4, 4, 512)   2048        ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 4, 4, 512)   2048        ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 4, 4, 512)    0           ['batch_normalization_17[0][0]', \n",
      "                                                                  'batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_14 (ReLU)                (None, 4, 4, 512)    0           ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 4, 4, 512)    2359808     ['re_lu_14[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 4, 4, 512)   2048        ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_15 (ReLU)                (None, 4, 4, 512)    0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 4, 4, 512)    2359808     ['re_lu_15[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 4, 4, 512)   2048        ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 4, 4, 512)    0           ['batch_normalization_19[0][0]', \n",
      "                                                                  're_lu_14[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_16 (ReLU)                (None, 4, 4, 512)    0           ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 1, 1, 512)   0           ['re_lu_16[0][0]']               \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 512)          0           ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 10)           5130        ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11,188,362\n",
      "Trainable params: 11,178,762\n",
      "Non-trainable params: 9,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n    history = model.fit(train_gen,\\n               batch_size=batch_size,\\n               epochs=200,\\n               verbose=1,\\n               validation_data=(test_images, test_labels),\\n               callbacks=[checkpoint]) #add/remove lr scheduler here\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    batch_size = 128\n",
    "    #loosely following the paper: : 4 pixels are padded on each side,\n",
    "    #and a 32Ã—32 crop is randomly sampled from the padded\n",
    "    #image or its horizontal flip. In this case we dont pad but sample from 4 possible shifts (for each direction)\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "                featurewise_center=False,\n",
    "                samplewise_center=False,\n",
    "                featurewise_std_normalization=False,\n",
    "                samplewise_std_normalization=False,\n",
    "                zca_whitening=False,\n",
    "                width_shift_range=4, #4 pixel padding\n",
    "                height_shift_range=4,\n",
    "                horizontal_flip=True,  # randomly flip images horizontally\n",
    "                vertical_flip=False,\n",
    "            )\n",
    "    print('Data Augmentation...')\n",
    "    train_gen = datagen.flow(train_images, train_labels, batch_size=batch_size)\n",
    "\n",
    "    #Build model, set optimizations\n",
    "    model = ResNet18()\n",
    "    #model = load_model(\"....h5\"), IF WANT TO CONTINUE TRAINING\n",
    "    \n",
    "    model.build(input_shape=(None, 32, 32, 3)) #Cifar-10 shape\n",
    "    model.summary()    \n",
    "    #opt = Adam(learning_rate=1e-2) \n",
    "    opt = SGD(learning_rate=0.1, momentum=0.9, decay=1e-4)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Initially ES was used but to ensure the maximum possible accuracy we ended up training for a lot of epochs anyway\n",
    "    #es = EarlyStopping(patience=20, restore_best_weights=True, monitor=\"val_accuracy\")\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filepath='avg_pool_model.h5', #change here saved model name    \n",
    "        monitor='val_accuracy',      \n",
    "        save_best_only=True,         \n",
    "        mode='max',                  \n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    def lr_schedule(epoch, lr):\n",
    "        if(epoch % 100 == 0):\n",
    "            new_lr = 0.1 * lr\n",
    "            print(\"Learning rate is\", new_lr)\n",
    "            return new_lr\n",
    "        return lr\n",
    "\n",
    "    lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "    #fit and evaluate\n",
    "\n",
    "    history = model.fit(train_gen,\n",
    "               batch_size=batch_size,\n",
    "               epochs=200,\n",
    "               verbose=1,\n",
    "               validation_data=(test_images, test_labels),\n",
    "               callbacks=[checkpoint]) #add/remove lr scheduler here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 8s 88ms/step - loss: 0.4861 - accuracy: 0.9275\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.48611411452293396, 0.9275000095367432]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"avg_pool_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
