{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pip in /home/jovyan/.local/lib/python3.8/site-packages (24.3.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (1.23.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (3.7.5)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.8/dist-packages (2.11.0)\n",
      "Requirement already satisfied: tensorflow[and-cuda] in /usr/local/lib/python3.8/dist-packages (2.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/lib/python3/dist-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/lib/python3/dist-packages (from matplotlib) (1.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (6.4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: tensorflow 2.11.0 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow[and-cuda]) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow[and-cuda]) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow[and-cuda]) (24.3.25)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow[and-cuda]) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow[and-cuda]) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow[and-cuda]) (1.62.2)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow[and-cuda]) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow[and-cuda]) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow[and-cuda]) (3.3.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/jovyan/.local/lib/python3.8/site-packages (from tensorflow[and-cuda]) (3.19.6)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow[and-cuda]) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow[and-cuda]) (1.14.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow[and-cuda]) (2.11.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow[and-cuda]) (2.11.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow[and-cuda]) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow[and-cuda]) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow[and-cuda]) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow[and-cuda]) (0.34.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow[and-cuda]) (0.43.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=3.2.0->matplotlib) (3.18.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow[and-cuda]) (2.29.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow[and-cuda]) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow[and-cuda]) (3.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow[and-cuda]) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow[and-cuda]) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow[and-cuda]) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow[and-cuda]) (3.0.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow[and-cuda]) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow[and-cuda]) (0.2.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow[and-cuda]) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow[and-cuda]) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow[and-cuda]) (7.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow[and-cuda]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow[and-cuda]) (2.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow[and-cuda]) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow[and-cuda]) (2019.11.28)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow[and-cuda]) (2.1.5)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow[and-cuda]) (3.2.2)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/lib/python3/dist-packages (from rsa<5,>=3.1.4->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow[and-cuda]) (0.4.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install --upgrade pip\n",
    "pip install numpy matplotlib keras tensorflow[and-cuda]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense, Flatten, BatchNormalization, Add, Input\n",
    "from keras.activations import relu\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    }
   ],
   "source": [
    "tf.debugging.set_log_device_placement(False)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "index_to_use = [1, 2, 3]\n",
    "device_names = [f'/GPU:{i}' for i in index_to_use]\n",
    "strategy = tf.distribute.MirroredStrategy(devices=device_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "#CIFAR-10 dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "print(train_images.shape)\n",
    "train_images = train_images.reshape(train_images.shape[0], 32, 32, 3) #ensure shape 32 W x 32 H x 3 channels for each image\n",
    "test_images = test_images.reshape(test_images.shape[0], 32, 32, 3)\n",
    "\n",
    "#range 0-1\n",
    "train_images = train_images.astype('float32') / 255.0\n",
    "test_images = test_images.astype('float32') / 255.0\n",
    "\n",
    "#One-hot encoding labels\n",
    "train_labels = to_categorical(train_labels, 10)\n",
    "test_labels = to_categorical(test_labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#currently trying ResNet18, according to paper: https://arxiv.org/pdf/1512.03385.pdf\n",
    "class ResNetBlock(Model): #inherits from Model class\n",
    "    def __init__(self, n_filters, kernel_size = (3, 3), kernel_init = 'HeNormal', downsample=False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.downsample = downsample\n",
    "        self.kernel_size = kernel_size\n",
    "        self.n_filters = n_filters\n",
    "        self.strides = [2, 1] if downsample else [1, 1] \n",
    "        self.kernel_init = kernel_init\n",
    "    \n",
    "        self.conv1 = Conv2D(self.n_filters, self.kernel_size, strides=self.strides[0], padding='same', activation='relu',\n",
    "                             kernel_initializer=self.kernel_init)\n",
    "        self.bn1 = BatchNormalization() # batch normalization after every convolutional layer\n",
    "        self.conv2 = Conv2D(self.n_filters, self.kernel_size, strides=self.strides[1], padding='same', activation='relu',\n",
    "                             kernel_initializer=self.kernel_init)\n",
    "        self.bn2 = BatchNormalization()\n",
    "        \n",
    "        if self.downsample: # the shortcut connection should also match the dimensions (convolution with a (1,1) kernel and stride of 2)\n",
    "            self.residual_conv = Conv2D(filters=self.n_filters, strides=2, kernel_size=(1, 1), kernel_initializer=self.kernel_init, padding=\"same\")\n",
    "            self.residual_bn = BatchNormalization()\n",
    "        \n",
    "        self.add = Add()\n",
    "\n",
    "    \n",
    "    def call(self, inputs): #forward pass (overriding parent class)\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x)\n",
    "        x = relu(x) #had forgotten this\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        \n",
    "        if self.downsample: \n",
    "            res = self.residual_conv(inputs)\n",
    "            res = self.residual_bn(res)\n",
    "        else:\n",
    "            res = inputs #no need to change dimensions\n",
    "        \n",
    "        x = self.add([x, res]) #merge block output with shortcut connection (residual path)\n",
    "        # pretty much same as x + residual, simply adding the two tensors\n",
    "        out = relu(x)\n",
    "        return out \n",
    "    \n",
    "class ResNet18(Model):\n",
    "    def __init__(self, n_classes=10, **kwargs): #default 10 classes for CIFAR-10\n",
    "        super().__init__(**kwargs)\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        #initial part\n",
    "        self.conv1 = Conv2D(kernel_size=(3, 3), strides=1, filters=64, padding='same', activation='relu',\n",
    "                            kernel_initializer='HeNormal')\n",
    "        self.bn1 = BatchNormalization()\n",
    "        \n",
    "        #blocks -> 2 x 2 blocks x 4 stages conv layers\n",
    "        # \"Downsampling is performed by conv3 1, conv4 1, and conv5 1 with a stride of 2.\"\n",
    "        #self.pool1 = MaxPooling2D(pool_size=(3, 3), strides=2, padding='same') -> removing this for cifar-10 \n",
    "        self.conv2_1 = ResNetBlock(n_filters=64) #conv2_x blocks have no downsampling\n",
    "        self.conv2_2 = ResNetBlock(n_filters=64)\n",
    "\n",
    "        self.conv3_1 = ResNetBlock(n_filters=128, downsample=True) #<-\n",
    "        self.conv3_2 = ResNetBlock(n_filters=128)\n",
    "\n",
    "        self.conv4_1 = ResNetBlock(n_filters=256, downsample=True) #<-\n",
    "        self.conv4_2 = ResNetBlock(n_filters=256)\n",
    "        \n",
    "        self.conv5_1 = ResNetBlock(n_filters=512, downsample=True) #<-\n",
    "        self.conv5_2 = ResNetBlock(n_filters=512)\n",
    "\n",
    "        #final part\n",
    "        self.avg_pool = GlobalAveragePooling2D()\n",
    "        self.fc = Dense(self.n_classes, activation='softmax')\n",
    "\n",
    "    def call(self, inputs): #forward pass\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x)\n",
    "        x = relu(x) # had forgotten this\n",
    "        #x = self.pool1(x)\n",
    "        for block in [self.conv2_1, self.conv2_2, self.conv3_1, self.conv3_2, self.conv4_1, self.conv4_2, self.conv5_1, self.conv5_2]:\n",
    "            x = block(x)\n",
    "        x = self.avg_pool(x)\n",
    "        out = self.fc(x)\n",
    "        return out  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# functional API instead:\n",
    "# Define ResNetBlock as a function\n",
    "def ResNetBlock(x, n_filters, kernel_size=(3, 3), kernel_init='HeNormal', downsample=False):\n",
    "    strides = [2, 1] if downsample else [1, 1]\n",
    "    \n",
    "    # Residual connection - if downsampling, apply to the original input\n",
    "    if downsample:\n",
    "        res = Conv2D(n_filters, kernel_size=(1, 1), strides=2, padding='same', kernel_initializer=kernel_init)(x)  # Apply downsampling to original input\n",
    "        res = BatchNormalization()(res)\n",
    "    else:\n",
    "        res = x  # When not downsampling, residual is just the output of the block\n",
    "    \n",
    "    # First convolution\n",
    "    x = Conv2D(n_filters, kernel_size, strides=strides[0], padding='same', kernel_initializer=kernel_init)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = relu(x)\n",
    "        \n",
    "    # Second convolution\n",
    "    x = Conv2D(n_filters, kernel_size, strides=strides[1], padding='same', kernel_initializer=kernel_init)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Add the residual connection (skip connection)\n",
    "    x = Add()([x, res])\n",
    "    x = relu(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "# Create the ResNet18 model using the functional API\n",
    "def ResNet18(input_shape=(32, 32, 3), n_classes=10):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    \n",
    "    # Initial part\n",
    "    x = Conv2D(64, (3, 3), strides=1, padding='same', activation='relu', kernel_initializer='HeNormal')(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = relu(x)\n",
    "    \n",
    "    # Blocks - 2 x 2 blocks x 4 stages of convolution layers\n",
    "    x = ResNetBlock(x, 64, downsample=False)  # 64 filters, no downsampling\n",
    "    x = ResNetBlock(x, 64, downsample=False)\n",
    "    \n",
    "    x = ResNetBlock(x, 128, downsample=True)  # 128 filters, with downsampling\n",
    "    x = ResNetBlock(x, 128, downsample=False)\n",
    "    \n",
    "    x = ResNetBlock(x, 256, downsample=True)  # 256 filters, with downsampling\n",
    "    x = ResNetBlock(x, 256, downsample=False)\n",
    "    \n",
    "    x = ResNetBlock(x, 512, downsample=True)  # 512 filters, with downsampling\n",
    "    x = ResNetBlock(x, 512, downsample=False)\n",
    "\n",
    "    # Final part\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    output = Dense(n_classes, activation='softmax')(x)\n",
    "    \n",
    "    # Create the complete model\n",
    "    model = Model(inputs=input_tensor, outputs=output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Augmentation...\n",
      "Model: \"res_net18_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_60 (Conv2D)          multiple                  1792      \n",
      "                                                                 \n",
      " batch_normalization_60 (Bat  multiple                 256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " res_net_block_24 (ResNetBlo  multiple                 74368     \n",
      " ck)                                                             \n",
      "                                                                 \n",
      " res_net_block_25 (ResNetBlo  multiple                 74368     \n",
      " ck)                                                             \n",
      "                                                                 \n",
      " res_net_block_26 (ResNetBlo  multiple                 231296    \n",
      " ck)                                                             \n",
      "                                                                 \n",
      " res_net_block_27 (ResNetBlo  multiple                 296192    \n",
      " ck)                                                             \n",
      "                                                                 \n",
      " res_net_block_28 (ResNetBlo  multiple                 921344    \n",
      " ck)                                                             \n",
      "                                                                 \n",
      " res_net_block_29 (ResNetBlo  multiple                 1182208   \n",
      " ck)                                                             \n",
      "                                                                 \n",
      " res_net_block_30 (ResNetBlo  multiple                 3677696   \n",
      " ck)                                                             \n",
      "                                                                 \n",
      " res_net_block_31 (ResNetBlo  multiple                 4723712   \n",
      " ck)                                                             \n",
      "                                                                 \n",
      " global_average_pooling2d_3   multiple                 0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_3 (Dense)             multiple                  5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,188,362\n",
      "Trainable params: 11,178,762\n",
      "Non-trainable params: 9,600\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 17:41:31.285180: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorDataset/_1\"\n",
      "op: \"TensorDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 1\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\022TensorDataset:1042\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT32\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate is 0.10000000149011612\n",
      "Epoch 1/200\n",
      "INFO:tensorflow:batch_all_reduce: 82 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 82 all-reduces with algorithm = nccl, num_packs = 1\n",
      "391/391 [==============================] - 54s 102ms/step - loss: 2.1293 - accuracy: 0.3314 - val_loss: 1.6392 - val_accuracy: 0.3960 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 39s 99ms/step - loss: 1.4269 - accuracy: 0.4831 - val_loss: 1.4007 - val_accuracy: 0.5176 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 38s 96ms/step - loss: 1.2164 - accuracy: 0.5633 - val_loss: 1.4500 - val_accuracy: 0.5064 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 38s 96ms/step - loss: 1.0459 - accuracy: 0.6274 - val_loss: 1.0745 - val_accuracy: 0.6281 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 37s 96ms/step - loss: 0.8939 - accuracy: 0.6840 - val_loss: 1.0247 - val_accuracy: 0.6447 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 38s 97ms/step - loss: 0.7901 - accuracy: 0.7243 - val_loss: 1.2144 - val_accuracy: 0.6195 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 39s 99ms/step - loss: 0.7123 - accuracy: 0.7507 - val_loss: 0.8361 - val_accuracy: 0.7209 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 39s 99ms/step - loss: 0.6516 - accuracy: 0.7736 - val_loss: 0.6631 - val_accuracy: 0.7728 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 39s 99ms/step - loss: 0.5907 - accuracy: 0.7952 - val_loss: 0.7877 - val_accuracy: 0.7588 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 39s 99ms/step - loss: 0.5551 - accuracy: 0.8064 - val_loss: 0.7511 - val_accuracy: 0.7404 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 39s 99ms/step - loss: 0.5301 - accuracy: 0.8150 - val_loss: 0.6503 - val_accuracy: 0.7801 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 39s 99ms/step - loss: 0.4759 - accuracy: 0.8352 - val_loss: 0.6717 - val_accuracy: 0.7772 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 38s 98ms/step - loss: 0.4435 - accuracy: 0.8448 - val_loss: 0.5155 - val_accuracy: 0.8254 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 39s 99ms/step - loss: 0.4072 - accuracy: 0.8573 - val_loss: 0.8596 - val_accuracy: 0.7391 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 39s 99ms/step - loss: 0.3858 - accuracy: 0.8662 - val_loss: 0.5076 - val_accuracy: 0.8326 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 39s 99ms/step - loss: 0.3647 - accuracy: 0.8720 - val_loss: 0.5666 - val_accuracy: 0.8078 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 39s 99ms/step - loss: 0.3452 - accuracy: 0.8798 - val_loss: 0.5109 - val_accuracy: 0.8268 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 39s 100ms/step - loss: 0.3266 - accuracy: 0.8850 - val_loss: 0.4677 - val_accuracy: 0.8427 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 39s 99ms/step - loss: 0.3024 - accuracy: 0.8934 - val_loss: 0.4750 - val_accuracy: 0.8416 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 39s 99ms/step - loss: 0.2876 - accuracy: 0.8999 - val_loss: 0.5110 - val_accuracy: 0.8319 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 39s 100ms/step - loss: 0.2717 - accuracy: 0.9043 - val_loss: 1.4812 - val_accuracy: 0.8464 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 39s 100ms/step - loss: 0.2579 - accuracy: 0.9089 - val_loss: 0.4460 - val_accuracy: 0.8595 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 39s 99ms/step - loss: 0.2401 - accuracy: 0.9152 - val_loss: 0.5077 - val_accuracy: 0.8420 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 38s 97ms/step - loss: 0.2294 - accuracy: 0.9187 - val_loss: 0.4165 - val_accuracy: 0.8658 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 38s 97ms/step - loss: 0.2155 - accuracy: 0.9257 - val_loss: 0.9575 - val_accuracy: 0.8601 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 39s 99ms/step - loss: 0.2036 - accuracy: 0.9284 - val_loss: 51.8934 - val_accuracy: 0.8520 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 39s 100ms/step - loss: 0.1953 - accuracy: 0.9306 - val_loss: 86.2496 - val_accuracy: 0.8659 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 39s 99ms/step - loss: 0.1799 - accuracy: 0.9364 - val_loss: 113.4786 - val_accuracy: 0.8558 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 39s 98ms/step - loss: 0.1722 - accuracy: 0.9402 - val_loss: 323.6813 - val_accuracy: 0.8657 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 39s 99ms/step - loss: 0.1599 - accuracy: 0.9430 - val_loss: 0.4240 - val_accuracy: 0.8735 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 39s 99ms/step - loss: 0.1542 - accuracy: 0.9453 - val_loss: 49.4457 - val_accuracy: 0.8586 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 39s 99ms/step - loss: 0.1436 - accuracy: 0.9494 - val_loss: 0.4814 - val_accuracy: 0.8622 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 39s 99ms/step - loss: 0.1373 - accuracy: 0.9506 - val_loss: 0.4376 - val_accuracy: 0.8735 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 38s 97ms/step - loss: 0.1300 - accuracy: 0.9532 - val_loss: 0.4359 - val_accuracy: 0.8749 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 39s 99ms/step - loss: 0.1243 - accuracy: 0.9554 - val_loss: 0.4296 - val_accuracy: 0.8831 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 39s 99ms/step - loss: 0.1195 - accuracy: 0.9577 - val_loss: 0.4354 - val_accuracy: 0.8748 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 39s 100ms/step - loss: 0.1135 - accuracy: 0.9604 - val_loss: 0.4179 - val_accuracy: 0.8838 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 39s 99ms/step - loss: 0.1102 - accuracy: 0.9607 - val_loss: 0.4328 - val_accuracy: 0.8770 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 39s 99ms/step - loss: 0.1025 - accuracy: 0.9638 - val_loss: 0.4455 - val_accuracy: 0.8810 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 39s 98ms/step - loss: 0.0962 - accuracy: 0.9662 - val_loss: 4.3561 - val_accuracy: 0.8801 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 39s 100ms/step - loss: 0.0943 - accuracy: 0.9670 - val_loss: 0.4102 - val_accuracy: 0.8874 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 39s 99ms/step - loss: 0.0843 - accuracy: 0.9707 - val_loss: 0.5072 - val_accuracy: 0.8704 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 39s 99ms/step - loss: 0.0825 - accuracy: 0.9704 - val_loss: 0.4729 - val_accuracy: 0.8793 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 38s 98ms/step - loss: 0.0742 - accuracy: 0.9747 - val_loss: 0.4361 - val_accuracy: 0.8824 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 38s 96ms/step - loss: 0.0767 - accuracy: 0.9738 - val_loss: 0.4836 - val_accuracy: 0.8798 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 39s 99ms/step - loss: 0.0710 - accuracy: 0.9750 - val_loss: 0.5205 - val_accuracy: 0.8898 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 39s 98ms/step - loss: 0.0656 - accuracy: 0.9770 - val_loss: 0.4301 - val_accuracy: 0.8853 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 39s 99ms/step - loss: 0.0623 - accuracy: 0.9786 - val_loss: 0.4546 - val_accuracy: 0.8922 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 39s 99ms/step - loss: 0.0624 - accuracy: 0.9775 - val_loss: 0.4429 - val_accuracy: 0.8853 - lr: 0.1000\n",
      "Learning rate is 0.10000000149011612\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 38s 98ms/step - loss: 0.0596 - accuracy: 0.9793 - val_loss: 0.4665 - val_accuracy: 0.8872 - lr: 0.1000\n",
      "Learning rate is 0.010000000149011612\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 39s 99ms/step - loss: 0.0464 - accuracy: 0.9835 - val_loss: 0.3812 - val_accuracy: 0.9027 - lr: 0.0100\n",
      "Learning rate is 0.0009999999776482583\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 39s 99ms/step - loss: 0.0379 - accuracy: 0.9873 - val_loss: 0.3779 - val_accuracy: 0.9035 - lr: 1.0000e-03\n",
      "Learning rate is 9.999999310821295e-05\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 39s 99ms/step - loss: 0.0392 - accuracy: 0.9866 - val_loss: 0.3783 - val_accuracy: 0.9034 - lr: 1.0000e-04\n",
      "Learning rate is 9.999999019782991e-06\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 39s 99ms/step - loss: 0.0398 - accuracy: 0.9869 - val_loss: 0.3784 - val_accuracy: 0.9027 - lr: 1.0000e-05\n",
      "Learning rate is 9.99999883788405e-07\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 39s 99ms/step - loss: 0.0391 - accuracy: 0.9868 - val_loss: 0.3785 - val_accuracy: 0.9038 - lr: 1.0000e-06\n",
      "Learning rate is 9.99999883788405e-08\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 37s 95ms/step - loss: 0.0391 - accuracy: 0.9873 - val_loss: 0.3784 - val_accuracy: 0.9037 - lr: 1.0000e-07\n",
      "Learning rate is 9.999998695775504e-09\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 38s 98ms/step - loss: 0.0392 - accuracy: 0.9874 - val_loss: 0.3789 - val_accuracy: 0.9034 - lr: 1.0000e-08\n",
      "Learning rate is 9.99999905104687e-10\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 39s 98ms/step - loss: 0.0397 - accuracy: 0.9860 - val_loss: 0.3777 - val_accuracy: 0.9033 - lr: 1.0000e-09\n",
      "Learning rate is 9.999998606957661e-11\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 39s 99ms/step - loss: 0.0383 - accuracy: 0.9874 - val_loss: 0.3790 - val_accuracy: 0.9031 - lr: 1.0000e-10\n",
      "Learning rate is 9.99999874573554e-12\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 39s 98ms/step - loss: 0.0397 - accuracy: 0.9860 - val_loss: 0.3787 - val_accuracy: 0.9037 - lr: 1.0000e-11\n",
      "Learning rate is 9.999999092680235e-13\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 39s 99ms/step - loss: 0.0381 - accuracy: 0.9875 - val_loss: 0.3784 - val_accuracy: 0.9035 - lr: 1.0000e-12\n",
      "Learning rate is 9.9999988758398e-14\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 39s 99ms/step - loss: 0.0398 - accuracy: 0.9864 - val_loss: 0.3793 - val_accuracy: 0.9028 - lr: 1.0000e-13\n",
      "Learning rate is 9.999999146890344e-15\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 39s 99ms/step - loss: 0.0397 - accuracy: 0.9865 - val_loss: 0.3790 - val_accuracy: 0.9035 - lr: 1.0000e-14\n",
      "Learning rate is 9.999998977483753e-16\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 39s 101ms/step - loss: 0.0386 - accuracy: 0.9867 - val_loss: 0.3786 - val_accuracy: 0.9036 - lr: 1.0000e-15\n",
      "Learning rate is 9.999998977483754e-17\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 39s 99ms/step - loss: 0.0385 - accuracy: 0.9872 - val_loss: 0.3778 - val_accuracy: 0.9032 - lr: 1.0000e-16\n",
      "Learning rate is 9.999998845134856e-18\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 39s 99ms/step - loss: 0.0374 - accuracy: 0.9876 - val_loss: 0.3780 - val_accuracy: 0.9032 - lr: 1.0000e-17\n",
      "Learning rate is 9.999999010570977e-19\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 38s 97ms/step - loss: 0.0387 - accuracy: 0.9869 - val_loss: 0.3782 - val_accuracy: 0.9037 - lr: 1.0000e-18\n",
      "Learning rate is 9.999999424161285e-20\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 39s 99ms/step - loss: 0.0392 - accuracy: 0.9866 - val_loss: 0.3782 - val_accuracy: 0.9035 - lr: 1.0000e-19\n",
      "Learning rate is 9.999999682655225e-21\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 39s 99ms/step - loss: 0.0389 - accuracy: 0.9870 - val_loss: 0.3784 - val_accuracy: 0.9039 - lr: 1.0000e-20\n",
      "Learning rate is 9.999999682655225e-22\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 39s 99ms/step - loss: 0.0392 - accuracy: 0.9871 - val_loss: 0.3783 - val_accuracy: 0.9036 - lr: 1.0000e-21\n",
      "Learning rate is 9.999999682655225e-23\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 39s 99ms/step - loss: 0.0376 - accuracy: 0.9873 - val_loss: 0.3797 - val_accuracy: 0.9032 - lr: 1.0000e-22\n",
      "Learning rate is 9.999999682655227e-24\n",
      "Epoch 72/200\n",
      "117/391 [=======>......................] - ETA: 25s - loss: 0.0398 - accuracy: 0.9868"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    batch_size = 128\n",
    "    datagen = ImageDataGenerator(\n",
    "                featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "                samplewise_center=False,  # set each sample mean to 0\n",
    "                featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "                samplewise_std_normalization=False,  # divide each input by its std\n",
    "                zca_whitening=False,  # apply ZCA whitening\n",
    "                # rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "                width_shift_range=4,  # randomly shift images horizontally (fraction of total width)\n",
    "                height_shift_range=4,  # randomly shift images vertically (fraction of total height)\n",
    "                horizontal_flip=True,  # randomly flip images\n",
    "                vertical_flip=False,  # randomly flip images\n",
    "            )\n",
    "    print('Data Augmentation...')\n",
    "    train_gen = datagen.flow(train_images, train_labels, batch_size=batch_size)\n",
    "    \n",
    "    #Build model, set optimizations\n",
    "    model = ResNet18()\n",
    "    model.build(input_shape=(None, 32, 32, 3)) #Cifar-10\n",
    "    model.summary()    \n",
    "    #optimizer = Adam(learning_rate=1e-2)\n",
    "    opt = SGD(learning_rate=0.1, momentum=0.9, decay=1e-4)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    es = EarlyStopping(patience=15, restore_best_weights=True, monitor=\"val_accuracy\")\n",
    "    def lr_schedule(epoch, lr):\n",
    "        if(epoch % 35 == 0):\n",
    "            new_lr = 0.1 * lr\n",
    "        print(\"Learning rate is\", new_lr)\n",
    "        return new_lr\n",
    "\n",
    "    lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "    #fit and evaluate\n",
    "    history = model.fit(train_gen,\n",
    "               batch_size=batch_size,\n",
    "               epochs=200,\n",
    "               verbose=1,\n",
    "               validation_data=(test_images, test_labels),\n",
    "               callbacks=[es, lr_scheduler])\n",
    "\n",
    "    print(\"Best inference accuracy, after early stopping:\")\n",
    "    model.evaluate(test_images, test_labels)\n",
    "    \n",
    "    model.save_weights(\"model.weights.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
