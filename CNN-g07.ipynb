{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./.venv/lib/python3.11/site-packages (2.0.2)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.11/site-packages (3.9.3)\n",
      "Requirement already satisfied: keras in ./.venv/lib/python3.11/site-packages (3.7.0)\n",
      "Requirement already satisfied: tensorflow[and-cuda] in ./.venv/lib/python3.11/site-packages (2.18.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.11/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.11/site-packages (from matplotlib) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.11/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.11/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.11/site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.11/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: absl-py in ./.venv/lib/python3.11/site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: rich in ./.venv/lib/python3.11/site-packages (from keras) (13.9.4)\n",
      "Requirement already satisfied: namex in ./.venv/lib/python3.11/site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in ./.venv/lib/python3.11/site-packages (from keras) (3.12.1)\n",
      "Requirement already satisfied: optree in ./.venv/lib/python3.11/site-packages (from keras) (0.13.1)\n",
      "Requirement already satisfied: ml-dtypes in ./.venv/lib/python3.11/site-packages (from keras) (0.4.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./.venv/lib/python3.11/site-packages (from tensorflow[and-cuda]) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in ./.venv/lib/python3.11/site-packages (from tensorflow[and-cuda]) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./.venv/lib/python3.11/site-packages (from tensorflow[and-cuda]) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./.venv/lib/python3.11/site-packages (from tensorflow[and-cuda]) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./.venv/lib/python3.11/site-packages (from tensorflow[and-cuda]) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./.venv/lib/python3.11/site-packages (from tensorflow[and-cuda]) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in ./.venv/lib/python3.11/site-packages (from tensorflow[and-cuda]) (5.29.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./.venv/lib/python3.11/site-packages (from tensorflow[and-cuda]) (2.32.3)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.11/site-packages (from tensorflow[and-cuda]) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./.venv/lib/python3.11/site-packages (from tensorflow[and-cuda]) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./.venv/lib/python3.11/site-packages (from tensorflow[and-cuda]) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./.venv/lib/python3.11/site-packages (from tensorflow[and-cuda]) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./.venv/lib/python3.11/site-packages (from tensorflow[and-cuda]) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./.venv/lib/python3.11/site-packages (from tensorflow[and-cuda]) (1.68.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in ./.venv/lib/python3.11/site-packages (from tensorflow[and-cuda]) (2.18.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./.venv/lib/python3.11/site-packages (from tensorflow[and-cuda]) (0.37.1)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.5.3.2 in ./.venv/lib/python3.11/site-packages (from tensorflow[and-cuda]) (12.5.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.5.82 in ./.venv/lib/python3.11/site-packages (from tensorflow[and-cuda]) (12.5.82)\n",
      "Requirement already satisfied: nvidia-cuda-nvcc-cu12==12.5.82 in ./.venv/lib/python3.11/site-packages (from tensorflow[and-cuda]) (12.5.82)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.5.82 in ./.venv/lib/python3.11/site-packages (from tensorflow[and-cuda]) (12.5.82)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.5.82 in ./.venv/lib/python3.11/site-packages (from tensorflow[and-cuda]) (12.5.82)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.3.0.75 in ./.venv/lib/python3.11/site-packages (from tensorflow[and-cuda]) (9.3.0.75)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.3.61 in ./.venv/lib/python3.11/site-packages (from tensorflow[and-cuda]) (11.2.3.61)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.6.82 in ./.venv/lib/python3.11/site-packages (from tensorflow[and-cuda]) (10.3.6.82)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.3.83 in ./.venv/lib/python3.11/site-packages (from tensorflow[and-cuda]) (11.6.3.83)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.1.3 in ./.venv/lib/python3.11/site-packages (from tensorflow[and-cuda]) (12.5.1.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./.venv/lib/python3.11/site-packages (from tensorflow[and-cuda]) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.5.82 in ./.venv/lib/python3.11/site-packages (from tensorflow[and-cuda]) (12.5.82)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./.venv/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow[and-cuda]) (0.45.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./.venv/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow[and-cuda]) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.venv/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow[and-cuda]) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./.venv/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow[and-cuda]) (3.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.11/site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.11/site-packages (from rich->keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./.venv/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow[and-cuda]) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# create virtual environment, activate it and install packages. If you already have a venv (from previous assignment for example) or\n",
    "# you're not even using one, you can skip this step.\n",
    "python3 -m venv .venv\n",
    "source .venv/bin/activate\n",
    "pip install numpy matplotlib keras tensorflow[and-cuda]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense, Flatten, BatchNormalization, Add\n",
    "from keras.activations import relu\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.regularizers import l1, l2\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "#CIFAR-10 dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "print(train_images.shape)\n",
    "train_images = train_images.reshape(train_images.shape[0], 32, 32, 3) #ensure shape 32 W x 32 H x 3 channels for each image\n",
    "test_images = test_images.reshape(test_images.shape[0], 32, 32, 3)\n",
    "\n",
    "#range 0-1\n",
    "train_images = train_images.astype('float32') / 255.0\n",
    "test_images = test_images.astype('float32') / 255.0\n",
    "\n",
    "#One-hot encoding labels\n",
    "train_labels = to_categorical(train_labels, 10)\n",
    "test_labels = to_categorical(test_labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#1st try LeNet-5 with batch normalization and l2 regularization - about 0.66 test validation with 0.0001 lambda and 0.001 le, I believe\n",
    "'''\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='best_weights.h5',\n",
    "    monitor='val_accuracy',              \n",
    "    save_best_only=True,                 \n",
    "    mode='max',  # Mode for monitoring, 'max' for accuracy\n",
    "    verbose=1                        \n",
    ")\n",
    "'''\n",
    "\"\"\"\n",
    "model = Sequential()\n",
    "l2_lambda = 0.0001\n",
    "model.add(Conv2D(6, kernel_size=(5, 5), activation='relu', input_shape=(32, 32, 3), kernel_regularizer=l2(l2_lambda))) #C1\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) #S1\n",
    "model.add(Conv2D(16, kernel_size=(5, 5), activation='relu', kernel_regularizer=l2(l2_lambda))) #C2\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) #S2\n",
    "model.add(Flatten())\n",
    "model.add(Dense(120, activation='relu', kernel_regularizer=l2(l2_lambda)))  # FC1\n",
    "model.add(Dense(84, activation='relu', kernel_regularizer=l2(l2_lambda)))  # FC2\n",
    "model.add(Dense(10, activation='softmax', kernel_regularizer=l2(l2_lambda)))  # FC3\n",
    "#model.summary()\n",
    " \"\"\"\n",
    "\n",
    "#currently trying ResNet18, according to paper: https://arxiv.org/pdf/1512.03385.pdf\n",
    "class ResNetBlock(Model): #inherits from Model class\n",
    "    def __init__(self, n_filters, kernel_size = (3, 3), kernel_init = 'HeNormal', downsample=False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.downsample = downsample\n",
    "        self.kernel_size = kernel_size\n",
    "        self.n_filters = n_filters\n",
    "        self.strides = [2, 1] if downsample else [1, 1] \n",
    "        self.kernel_init = kernel_init\n",
    "    \n",
    "        self.conv1 = Conv2D(self.n_filters, self.kernel_size, strides=self.strides[0], padding='same', activation='relu',\n",
    "                             kernel_initializer=self.kernel_init)\n",
    "        self.bn1 = BatchNormalization() # batch normalization after every convolutional layer\n",
    "        self.conv2 = Conv2D(self.n_filters, self.kernel_size, strides=self.strides[1], padding='same', activation='relu',\n",
    "                             kernel_initializer=self.kernel_init)\n",
    "        self.bn2 = BatchNormalization()\n",
    "        \n",
    "        if self.downsample: # the shortcut connection should also match the dimensions (convolution with a (1,1) kernel and stride of 2)\n",
    "            self.residual_conv = Conv2D(filters=self.n_filters, strides=2, kernel_size=(1, 1), kernel_initializer=self.kernel_init, padding=\"same\")\n",
    "            self.residual_bn = BatchNormalization()\n",
    "        \n",
    "        self.add = Add()\n",
    "\n",
    "    \n",
    "    def call(self, inputs): #forward pass (overriding parent class)\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        \n",
    "        if self.downsample: \n",
    "            res = self.residual_conv(inputs)\n",
    "            res = self.residual_bn(res)\n",
    "        else:\n",
    "            res = inputs #no need to change dimensions\n",
    "        \n",
    "        x = self.add([x, res]) #merge block output with shortcut connection (residual path)\n",
    "        # pretty much same as x + residual, simply adding the two tensors\n",
    "        out = relu(x)\n",
    "        return out \n",
    "    \n",
    "class ResNet18(Model):\n",
    "    def __init__(self, n_classes=10, **kwargs): #default 10 classes for CIFAR-10\n",
    "        super().__init__(**kwargs)\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        #initial part\n",
    "        self.conv1 = Conv2D(kernel_size=(3, 3), strides=1, filters=64, padding='same', activation='relu',\n",
    "                            kernel_initializer='HeNormal')\n",
    "        self.bn1 = BatchNormalization()\n",
    "        \n",
    "        #blocks -> 2 x 2 blocks x 4 stages conv layers\n",
    "        # \"Downsampling is performed by conv3 1, conv4 1, and conv5 1 with a stride of 2.\"\n",
    "        self.pool1 = MaxPooling2D(pool_size=(3, 3), strides=2, padding='same')\n",
    "        self.conv2_1 = ResNetBlock(n_filters=64) #conv2_x blocks have no downsampling\n",
    "        self.conv2_2 = ResNetBlock(n_filters=64)\n",
    "\n",
    "        self.conv3_1 = ResNetBlock(n_filters=128, downsample=True) #<-\n",
    "        self.conv3_2 = ResNetBlock(n_filters=128)\n",
    "\n",
    "        self.conv4_1 = ResNetBlock(n_filters=256, downsample=True) #<-\n",
    "        self.conv4_2 = ResNetBlock(n_filters=256)\n",
    "        \n",
    "        self.conv5_1 = ResNetBlock(n_filters=512, downsample=True) #<-\n",
    "        self.conv5_2 = ResNetBlock(n_filters=512)\n",
    "\n",
    "        #final part\n",
    "        self.avg_pool = GlobalAveragePooling2D()\n",
    "        self.fc = Dense(self.n_classes, activation='softmax')\n",
    "\n",
    "    def call(self, inputs): #forward pass\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x)\n",
    "        x = self.pool1(x)\n",
    "        for block in [self.conv2_1, self.conv2_2, self.conv3_1, self.conv3_2, self.conv4_1, self.conv4_2, self.conv5_1, self.conv5_2]:\n",
    "            x = block(x)\n",
    "        x = self.avg_pool(x)\n",
    "        out = self.fc(x)\n",
    "        return out   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "391/391 [==============================] - 15s 31ms/step - loss: 2.1434 - accuracy: 0.3793 - val_loss: 1.5319 - val_accuracy: 0.4482\n",
      "Epoch 2/100\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 1.3339 - accuracy: 0.5495 - val_loss: 1.3289 - val_accuracy: 0.5386\n",
      "Epoch 3/100\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 1.0598 - accuracy: 0.6342 - val_loss: 1.4916 - val_accuracy: 0.5023\n",
      "Epoch 4/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.8584 - accuracy: 0.6966 - val_loss: 0.9707 - val_accuracy: 0.6586\n",
      "Epoch 5/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.7081 - accuracy: 0.7493 - val_loss: 0.9532 - val_accuracy: 0.6754\n",
      "Epoch 6/100\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.5757 - accuracy: 0.8001 - val_loss: 1.0067 - val_accuracy: 0.6748\n",
      "Epoch 7/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.4605 - accuracy: 0.8368 - val_loss: 1.2071 - val_accuracy: 0.6463\n",
      "Epoch 8/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.3489 - accuracy: 0.8765 - val_loss: 0.8972 - val_accuracy: 0.7187\n",
      "Epoch 9/100\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 0.2485 - accuracy: 0.9129 - val_loss: 1.1400 - val_accuracy: 0.6965\n",
      "Epoch 10/100\n",
      "391/391 [==============================] - 10s 27ms/step - loss: 0.1735 - accuracy: 0.9397 - val_loss: 1.1566 - val_accuracy: 0.7135\n",
      "Epoch 11/100\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.1223 - accuracy: 0.9571 - val_loss: 1.3022 - val_accuracy: 0.7100\n",
      "Epoch 12/100\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.0782 - accuracy: 0.9730 - val_loss: 1.4334 - val_accuracy: 0.7004\n",
      "Epoch 13/100\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.0584 - accuracy: 0.9804 - val_loss: 1.3728 - val_accuracy: 0.7276\n",
      "Epoch 14/100\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.0389 - accuracy: 0.9871 - val_loss: 1.4281 - val_accuracy: 0.7354\n",
      "Epoch 15/100\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 0.0283 - accuracy: 0.9909 - val_loss: 1.3730 - val_accuracy: 0.7431\n",
      "Epoch 16/100\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.0190 - accuracy: 0.9943 - val_loss: 1.4781 - val_accuracy: 0.7351\n",
      "Epoch 17/100\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.0148 - accuracy: 0.9954 - val_loss: 1.8399 - val_accuracy: 0.7334\n",
      "Epoch 18/100\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.0090 - accuracy: 0.9974 - val_loss: 1.4897 - val_accuracy: 0.7521\n",
      "Epoch 19/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0084 - accuracy: 0.9975 - val_loss: 1.6139 - val_accuracy: 0.7415\n",
      "Epoch 20/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0118 - accuracy: 0.9964 - val_loss: 1.5725 - val_accuracy: 0.7524\n",
      "Epoch 21/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 1.6560 - val_accuracy: 0.7479\n",
      "Epoch 22/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 1.5647 - val_accuracy: 0.7533\n",
      "Epoch 23/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 1.5294 - val_accuracy: 0.7591\n",
      "Epoch 24/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 1.6623 - val_accuracy: 0.7481\n",
      "Epoch 25/100\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 1.5603 - val_accuracy: 0.7587\n",
      "Epoch 26/100\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 1.5562 - val_accuracy: 0.7584\n",
      "Epoch 27/100\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 9.9618e-04 - accuracy: 0.9999 - val_loss: 1.5635 - val_accuracy: 0.7596\n",
      "Epoch 28/100\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 9.3589e-04 - accuracy: 0.9998 - val_loss: 1.5700 - val_accuracy: 0.7596\n",
      "Epoch 29/100\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 5.5736e-04 - accuracy: 0.9999 - val_loss: 1.5837 - val_accuracy: 0.7603\n",
      "Epoch 30/100\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 3.7467e-04 - accuracy: 1.0000 - val_loss: 1.5871 - val_accuracy: 0.7608\n",
      "Epoch 31/100\n",
      "391/391 [==============================] - 10s 27ms/step - loss: 4.3786e-04 - accuracy: 0.9999 - val_loss: 1.5926 - val_accuracy: 0.7622\n",
      "Epoch 32/100\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 3.7233e-04 - accuracy: 0.9999 - val_loss: 1.6002 - val_accuracy: 0.7624\n",
      "Epoch 33/100\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 3.6960e-04 - accuracy: 0.9999 - val_loss: 1.5999 - val_accuracy: 0.7630\n",
      "Epoch 34/100\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 3.5775e-04 - accuracy: 1.0000 - val_loss: 1.6042 - val_accuracy: 0.7613\n",
      "Epoch 35/100\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 5.2169e-04 - accuracy: 0.9999 - val_loss: 1.6415 - val_accuracy: 0.7582\n",
      "Epoch 36/100\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 4.4704e-04 - accuracy: 0.9999 - val_loss: 1.6533 - val_accuracy: 0.7579\n",
      "Epoch 37/100\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 3.1726e-04 - accuracy: 1.0000 - val_loss: 1.6221 - val_accuracy: 0.7644\n",
      "Epoch 38/100\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 4.2695e-04 - accuracy: 0.9999 - val_loss: 1.6223 - val_accuracy: 0.7639\n",
      "Epoch 39/100\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 3.9604e-04 - accuracy: 0.9999 - val_loss: 1.6316 - val_accuracy: 0.7614\n",
      "Epoch 40/100\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 3.7800e-04 - accuracy: 0.9999 - val_loss: 1.6273 - val_accuracy: 0.7619\n",
      "Epoch 41/100\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 2.6202e-04 - accuracy: 1.0000 - val_loss: 1.6334 - val_accuracy: 0.7629\n",
      "Epoch 42/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 2.2982e-04 - accuracy: 1.0000 - val_loss: 1.6379 - val_accuracy: 0.7612\n",
      "Best inference accuracy, after early stopping:\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 1.6221 - accuracy: 0.7645\n",
      "Model: \"res_net18_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_263 (Conv2D)         multiple                  1792      \n",
      "                                                                 \n",
      " batch_normalization_263 (Ba  multiple                 256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  multiple                 0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " res_net_block_107 (ResNetBl  multiple                 74368     \n",
      " ock)                                                            \n",
      "                                                                 \n",
      " res_net_block_108 (ResNetBl  multiple                 74368     \n",
      " ock)                                                            \n",
      "                                                                 \n",
      " res_net_block_109 (ResNetBl  multiple                 231296    \n",
      " ock)                                                            \n",
      "                                                                 \n",
      " res_net_block_110 (ResNetBl  multiple                 296192    \n",
      " ock)                                                            \n",
      "                                                                 \n",
      " res_net_block_111 (ResNetBl  multiple                 921344    \n",
      " ock)                                                            \n",
      "                                                                 \n",
      " res_net_block_112 (ResNetBl  multiple                 1182208   \n",
      " ock)                                                            \n",
      "                                                                 \n",
      " res_net_block_113 (ResNetBl  multiple                 3677696   \n",
      " ock)                                                            \n",
      "                                                                 \n",
      " res_net_block_114 (ResNetBl  multiple                 4723712   \n",
      " ock)                                                            \n",
      "                                                                 \n",
      " global_average_pooling2d_13  multiple                 0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dense_13 (Dense)            multiple                  5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,188,362\n",
      "Trainable params: 11,178,762\n",
      "Non-trainable params: 9,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = ResNet18(10)\n",
    "model.build(input_shape=(None, 32, 32, 3)) #Cifar-10\n",
    "#optimizer = Adam(learning_rate=1e-2)\n",
    "opt = SGD(learning_rate=0.1, momentum=0.9, decay=5e-4) #stochastic grad descent with l2 regularization (decay)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "es = EarlyStopping(patience=5, restore_best_weights=True, monitor=\"val_accuracy\")\n",
    "history = output = model.fit(train_images,\n",
    "           train_labels,\n",
    "           batch_size=128,\n",
    "           epochs=100,\n",
    "           verbose=1,\n",
    "           validation_data=(test_images, test_labels),\n",
    "           callbacks=[es])\n",
    "\n",
    "print(\"Best inference accuracy, after early stopping:\")\n",
    "model.evaluate(test_images, test_labels)\n",
    "model.save_weights(\"model.weights.h5\")\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
